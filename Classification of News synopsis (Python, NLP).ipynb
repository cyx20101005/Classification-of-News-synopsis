{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of News Synopsis\n",
    "\n",
    "There are 20 classes of News synopsis for this dataset. Each class has many text documents.   \n",
    "The goal of this project:\n",
    "- Use the training data to learn a text document classifier and apply this classifier on all the test data to have them properly labeled \n",
    "- Compare the model label of each test doc to the test gold label and compute the evaluation. Each sub dirâ€™s name is the gold label for all the text documents under it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhZ3_Xj1creQ"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import errno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 361,
     "status": "error",
     "timestamp": 1566530151204,
     "user": {
      "displayName": "YIXIN CAO",
      "photoUrl": "",
      "userId": "07411751685458409219"
     },
     "user_tz": 420
    },
    "id": "oCf7lBz2crev",
    "outputId": "5c3793ed-0920-4ef3-c1a4-62633e707afe"
   },
   "outputs": [],
   "source": [
    "# Modify the name of the folders which contain '.'\n",
    "\n",
    "path_train = 'data/train'\n",
    "path_test = 'data/test'\n",
    "def changename(path):\n",
    "    for file in os.listdir(path):\n",
    "        name = os.path.basename(file)\n",
    "        new_name = []\n",
    "        for item in name:\n",
    "            if item == '.':\n",
    "                new_name.append('_')\n",
    "            else:\n",
    "                new_name.append(item)\n",
    "        os.rename(path + '/' + name, path + '/' + ''.join(new_name))\n",
    "        \n",
    "changename(path_train)\n",
    "changename(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z46u09Tmcre_",
    "outputId": "3280a9ac-480b-43ec-e304-ebe510a7c9a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: matt@galaxy.nsc.com (Matt Freivald x8043...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: Clinton-HQ@Campaign92.Org (The White Hou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: onr@netcom.com (D. Owen Rowley)\\nSubject...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: asper@calvin.uucp (Alan E. Asper)\\nSubje...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: munoz@sweetpea.jsc.nasa.gov (tomas o mun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Label\n",
       "0  From: matt@galaxy.nsc.com (Matt Freivald x8043...      0\n",
       "1  From: Clinton-HQ@Campaign92.Org (The White Hou...      0\n",
       "2  From: onr@netcom.com (D. Owen Rowley)\\nSubject...      0\n",
       "3  From: asper@calvin.uucp (Alan E. Asper)\\nSubje...      0\n",
       "4  From: munoz@sweetpea.jsc.nasa.gov (tomas o mun...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trasform data to csv format\n",
    "def trandf(path):\n",
    "    file = glob.glob(path)\n",
    "    list = []\n",
    "    for i in range(len(file)):\n",
    "        new_path = file[i] + '/*'\n",
    "        file1 = glob.glob(new_path)\n",
    "        list1 = []\n",
    "        for f in file1:\n",
    "            content = open(f).read()\n",
    "            list1.append(pd.DataFrame(data = {'Content': [content], 'Label' : [i]}))\n",
    "        comb = pd.concat(list1)\n",
    "        list.append(comb)\n",
    "    raw_data = pd.concat(list)\n",
    "    raw_data.to_csv('raw_data.csv')\n",
    "    df = pd.read_csv('raw_data.csv')\n",
    "    df = df.drop('Unnamed: 0', 1)\n",
    "    return df\n",
    "path_train1 = 'data/train/*'\n",
    "path_test1 = 'data/test/*'\n",
    "df_train = trandf(path_train1)\n",
    "df_test = trandf(path_test1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXBa_y_XcrfT",
    "outputId": "36bbb8cc-fd4d-47f2-8a5b-0525089ec5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/souyixin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "We use 179 stop-words form nltk library.\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u\"you're\"]\n"
     ]
    }
   ],
   "source": [
    "#import nltk to do tokenize and steming\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print ('We use ' + str(len(stopwords)) + ' stop-words form nltk library.')\n",
    "print (stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrSxTGJycrfd",
    "outputId": "0ecf6d9d-a636-482e-e149-c863065c2679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/souyixin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# Define tokenization and steming bys self\n",
    "def tokenization_and_stemming(text):\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word not in stopwords]\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dl7jDMtkcrfj",
    "outputId": "17333c89-1608-432e-d2e4-d86583c90133"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 234212)\t0.0156475619930839\n",
      "  (0, 234048)\t0.014648041461525459\n",
      "  (0, 233461)\t0.042976684048947764\n",
      "  (0, 233221)\t0.022714941974135414\n",
      "  (0, 233166)\t0.009662823667840199\n",
      "  (0, 233145)\t0.017491545568779736\n",
      "  (0, 231535)\t0.04447825039282544\n",
      "  (0, 230144)\t0.021488342024473882\n",
      "  (0, 230132)\t0.018972566377083725\n",
      "  (0, 228906)\t0.008487761719172118\n",
      "  (0, 228006)\t0.020221279760818993\n",
      "  (0, 227850)\t0.02223912519641272\n",
      "  (0, 227666)\t0.02678761843114096\n",
      "  (0, 227474)\t0.009348811140361337\n",
      "  (0, 225812)\t0.04086034515176468\n",
      "  (0, 225811)\t0.04086034515176468\n",
      "  (0, 225799)\t0.025137743593085064\n",
      "  (0, 225205)\t0.01124645369764776\n",
      "  (0, 224288)\t0.020905989353605034\n",
      "  (0, 224287)\t0.040442559521637986\n",
      "  (0, 224286)\t0.04005575044503936\n",
      "  (0, 223674)\t0.013757947579735318\n",
      "  (0, 223011)\t0.015865168562402252\n",
      "  (0, 222710)\t0.021488342024473882\n",
      "  (0, 222546)\t0.033529694299523405\n",
      "  :\t:\n",
      "  (7760, 34705)\t0.07076644657002731\n",
      "  (7760, 34704)\t0.06928408035416041\n",
      "  (7760, 33979)\t0.06513081038331649\n",
      "  (7760, 33937)\t0.040300240402756024\n",
      "  (7760, 30682)\t0.0357722264829956\n",
      "  (7760, 19474)\t0.07076644657002731\n",
      "  (7760, 19473)\t0.07076644657002731\n",
      "  (7760, 19472)\t0.07076644657002731\n",
      "  (7760, 19468)\t0.07076644657002731\n",
      "  (7760, 19467)\t0.05909848555318268\n",
      "  (7760, 19457)\t0.049194251158713884\n",
      "  (7760, 17779)\t0.04632873099354559\n",
      "  (7760, 13524)\t0.07076644657002731\n",
      "  (7760, 13523)\t0.13856816070832081\n",
      "  (7760, 13522)\t0.2078522410624812\n",
      "  (7760, 13521)\t0.2078522410624812\n",
      "  (7760, 11461)\t0.034937596433905815\n",
      "  (7760, 4457)\t0.07076644657002731\n",
      "  (7760, 4456)\t0.07076644657002731\n",
      "  (7760, 4455)\t0.07076644657002731\n",
      "  (7760, 4454)\t0.07076644657002731\n",
      "  (7760, 4453)\t0.14153289314005463\n",
      "  (7760, 2215)\t0.04896838929109954\n",
      "  (7760, 779)\t0.06928408035416041\n",
      "  (7760, 731)\t0.027058064481602428\n"
     ]
    }
   ],
   "source": [
    "#CountVectorizer and TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer(max_df=0.8,max_features = 234585,\n",
    "                                 min_df=0, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenization_and_stemming, ngram_range=(1,3))\n",
    "\n",
    "Features_train = tfidf_model.fit_transform(df_train['Content'])\n",
    "Features_test = tfidf_model.transform(df_test['Content'])\n",
    "print(Features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6hDYubocrfq",
    "outputId": "c15268d0-2df8-480d-e7a0-21b9ddb3342d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7761, 234585)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pu78BxXjcrfu"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Cross validation\n",
    "models = [RandomForestClassifier(n_estimators = 200, max_depth = 3, random_state = 0), MultinomialNB(), LogisticRegression(random_state = 0)]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index = range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    scores = cross_val_score(model, Features_train, df_train['Label'], scoring = 'accuracy', cv = CV)\n",
    "    entries.append((model_name, scores.mean()))\n",
    "cv_df = pd.DataFrame(entries, columns = ['model_name',  'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rz0P-xxAcrfz",
    "outputId": "f6e8d389-40c1-49c1-814e-b1305d2c7ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model_name  accuracy\n",
      "0  RandomForestClassifier  0.293515\n",
      "1           MultinomialNB  0.873051\n",
      "2      LogisticRegression  0.899670\n"
     ]
    }
   ],
   "source": [
    "print(cv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2psJ45vjcrf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': (1, 5, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def print_grid_search_metrics(gs):\n",
    "    print (\"Best score: %0.3f\" % gs.best_score_)\n",
    "    print (\"Best parameters set:\")\n",
    "    best_parameters = gs.best_params_\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "parameters = {\n",
    "    'penalty':('l1', 'l2'), \n",
    "    'C':(1, 5, 10)\n",
    "}\n",
    "Grid_LR = GridSearchCV(LogisticRegression(),parameters, cv=5, n_jobs = -1)\n",
    "Grid_LR.fit(Features_train, df_train['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNVmBcQ-crf9",
    "outputId": "b99467f6-cda5-4363-c176-7a017f02a20b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.921\n",
      "Best parameters set:\n",
      "\tC: 10\n",
      "\tpenalty: 'l2'\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWIFUPpLcrgB"
   },
   "outputs": [],
   "source": [
    "best_LR_model = Grid_LR.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KRpBBEcjcrgD",
    "outputId": "84760ab9-e9c6-478e-caa9-7ee0078d29f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'alpha': array([0.10526, 0.21053, 0.31579, 0.42105, 0.52632, 0.63158, 0.73684,\n",
       "       0.84211, 0.94737, 1.05263, 1.15789, 1.26316, 1.36842, 1.47368,\n",
       "       1.57895, 1.68421, 1.78947, 1.89474, 2.     ])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = dict( alpha = np.linspace(0,2,20)[1:] )\n",
    "Grid_NB = GridSearchCV(MultinomialNB(), parameters, cv = 5, n_jobs = -1)\n",
    "Grid_NB.fit(Features_train, df_train['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6worN_T9crgL",
    "outputId": "71a2f29b-eba1-457f-ca19-c9bbe53e22e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.904\n",
      "Best parameters set:\n",
      "\talpha: 0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "print_grid_search_metrics(Grid_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CwOCKQ7ScrgP"
   },
   "outputs": [],
   "source": [
    "best_NB_model = Grid_NB.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iP50e2YMcrgS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score_LR = f1_score(df_test['Label'], best_LR_model.predict(Features_test), average = 'macro')\n",
    "f1_score_NB = f1_score(df_test['Label'], best_NB_model.predict(Features_test), average = 'macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAU8un_AcrgX",
    "outputId": "420f570a-c22a-4078-bb83-0c0ea83b626f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7805364042230845\n"
     ]
    }
   ],
   "source": [
    "print(f1_score_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbOWiH7fcrgf",
    "outputId": "f3ca30f1-1f89-48db-d12e-3c385e0dd8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366473050006917\n"
     ]
    }
   ],
   "source": [
    "print(f1_score_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atTt7sRlcrgi",
    "outputId": "40be42cb-2e1a-44a1-e28e-955b46055dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74       310\n",
      "          1       0.89      0.83      0.86       395\n",
      "          2       1.00      0.77      0.87       827\n",
      "          3       0.75      0.87      0.81       390\n",
      "          4       0.98      0.91      0.94       376\n",
      "          5       0.72      0.96      0.82       397\n",
      "          6       0.73      0.77      0.75       392\n",
      "          7       0.92      0.91      0.92       394\n",
      "          8       0.78      0.92      0.84       364\n",
      "          9       0.84      0.93      0.88       398\n",
      "         10       0.71      0.96      0.82       198\n",
      "         11       0.73      0.79      0.76       389\n",
      "         12       0.78      0.65      0.71       251\n",
      "         13       0.92      0.90      0.91       395\n",
      "         14       0.86      0.76      0.81       319\n",
      "         15       0.96      0.94      0.95       398\n",
      "         16       0.83      0.87      0.85       385\n",
      "         17       0.79      0.80      0.79       393\n",
      "         18       0.93      0.93      0.93       396\n",
      "         19       0.80      0.75      0.77       394\n",
      "\n",
      "avg / total       0.85      0.84      0.84      7761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(df_test['Label'], best_LR_model.predict(Features_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dagg4v4Wcrgn",
    "outputId": "8499f541-70a5-4a9d-ace2-a767bd6e4ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74       310\n",
      "          1       0.85      0.84      0.85       395\n",
      "          2       1.00      0.34      0.50       827\n",
      "          3       0.77      0.82      0.80       390\n",
      "          4       0.94      0.95      0.94       376\n",
      "          5       0.47      0.96      0.63       397\n",
      "          6       0.63      0.77      0.69       392\n",
      "          7       0.85      0.90      0.88       394\n",
      "          8       0.75      0.91      0.82       364\n",
      "          9       0.76      0.95      0.84       398\n",
      "         10       0.57      0.93      0.71       198\n",
      "         11       0.73      0.73      0.73       389\n",
      "         12       0.84      0.50      0.63       251\n",
      "         13       0.87      0.90      0.89       395\n",
      "         14       0.84      0.77      0.80       319\n",
      "         15       0.93      0.92      0.93       398\n",
      "         16       0.83      0.82      0.82       385\n",
      "         17       0.81      0.73      0.77       393\n",
      "         18       0.89      0.92      0.90       396\n",
      "         19       0.81      0.66      0.73       394\n",
      "\n",
      "avg / total       0.82      0.78      0.77      7761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(df_test['Label'], best_NB_model.predict(Features_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpLWKmpkcrgu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classification of News synopsis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
